---
icon: brain-circuit
description: >-
  A two week seminar about the ethics and philosophy behind AI that culminated
  with a proposal to build our own AI in the context of a solarpunk world!
cover: ../../.gitbook/assets/Screenshot 2024-11-23 181918.png
coverY: 26
layout:
  cover:
    visible: true
    size: hero
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
---

# Extended Intelligences

Faculty : Andres Colmenares, Pau Artigas

***



### Reflections



The seminar started with Andres introducing us to AI with a highly philosophical approach which I will admit, I wasn't expecting. I started the week thinking that the entire seminar would be exactly how the narrative about AI is presented - its the next best thing for humankind. a leap for technology. I understand that this may come off as sarcastic, but this is my general perception about Artificial intelligence. I have limited knowledge about it and I am intimidated by it, but I am also worried about the way it is taking over and seeping into our daily routines, increasing our dependance on AI.&#x20;

So when Andres started the seminar with a thought provoking presentation about technology, math and climate change, it got me really excited about where this week would take us. I found his approach and method refreshingly new. In the following days, we discussed more about the the physicality of AI like the data centers and how they work, and their impact on the environment. Each day ended with each of us sharing key learnings about the topics discussed that day which helped condense the overwhelming information. The first week concluded with each group proposing an idea for an AI in a  solarpunk world.

Pau started the second week with a much more practical approach. He explained to us the anatomy of AI, the programming, datasets, LLMs and what machine learning means. He taught us basic ways of using these datasets and models to try our hand at using them. We had to refine the ideas which we proposed last week and try to use Google Colab to program a small component of our proposal. Our group had a proposal to make community gardens accessible where people could go and take fruits/vegetable for free, and the basis of the entire concept were the ethics of Honorable Harvest. While we were brainstorming for ideas, everything that we could come up with did not require AI at all. I thought it was quite surprising that we were having such a hard time designing an AI. Maybe it was because we two of us in the group already had a bias against AI, I am not sure, but it was very interesting.&#x20;

Once we settled on what we were doing, Pau suggested us to research about multiagent systems. Throughout the process of refining the idea and getting it to work, a lot of ethical discussions came up in our group. What does it mean to code the honorable harvest ethics into our AI? How ethical is it to enforce these ethics on users? We finally reached a consensus that ethics should just be an environment and not a rule. The second week culminated with a presentation on the making of our AI and a demonstration.  &#x20;

Before this, I wasn't very sure about where I stand in the discourse of using AI, probably on the edge since I had less knowledge and more preconceived opinion. But through the two weeks, I realized that all the discussions were helping me situate myself better. I'm still skeptical about the use of AI tools, but these discussions definitely opened up a world of curiosity for me, critically thinking about using AI and the way we use it. For me, these two weeks dismantled the sterility of AI and made it seem more approachable. I think, the next time I work with AI, I would be more open to exploring its potential. I do still think there needs to be some ethical regulations on the way we use AI. I liked a phrase that Andres used - 'anthropomorphize' to discuss how we should be aware about looking at AI purely as a tool and not as an entity. The way that we use terminologies that personify AI is actually the scarier part of the equation that we have with technology. Language makes it almost human and hence almost as scary, if not more.&#x20;



**Link to the presentation**&#x20;

{% embed url="https://docs.google.com/presentation/d/1yfB8hbcEqHYPDVfYIKb6_ey23chUatqtnE8GyRNOMGA/edit#slide=id.p" %}

**Link to the documentation**



{% embed url="https://drive.google.com/drive/folders/1_Os3U3cdPO-ooZ1E3uiq6tG3alW8vziY" %}



